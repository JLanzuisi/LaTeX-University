\documentclass[twocolumn]{notasdeclase}

\newcommand{\inte}[4]{\int_{#1}^{#2} #3\, d#4}
%\newcommand{\id}[1]{\mathfrak{#1}}
\newcommand{\an}[1]{\mathcal{#1}}
\newcommand{\ve}[1]{\mathscr{#1}}
\newcommand{\vcsp}[1]{\mathcal{#1}}
\newcommand{\V}{\mathcal{V}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\Mn}[1]{\vcsp M_{n\t n}(\vcsp #1^n)}
\newcommand{\norm}{\lVert\phantom{a}\rVert}
\newcommand{\Norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\iprod}{\langle\phantom{x},\phantom{x}\rangle}
\newcommand{\Iprod}[2]{\left\langle#1,#2\right\rangle}
\newcommand{\Bform}{(\phantom{a},\phantom{a})}
\newcommand{\bform}[2]{(#1,#2)}
\newcommand{\inv}{^{-1}}
\newcommand{\ort}{^\perp}
\renewcommand{\t}{\times}
\newcommand{\dt}[2]{#1_1 #2 #1_2 #2 \dots #2 #1_n}
\newcommand{\Dt}[2]{(#1_1+#2_1)^2 + \dots + (#1_n+#2_n)^2}
\newcommand{\pd}[1]{\frac{\partial}{\partial #1}}
\newcommand{\pdd}[2]{\dfrac{\partial #1}{\partial #2}}
\newcommand{\pds}[2]{\dfrac{\partial^2 #1}{\partial #2^2}} 
\newcommand{\pdx}[3]{\dfrac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\der}[1]{\frac{d}{d#1}}
\newcommand{\pol}[1]{#1_n x^n + #1_{n-1} x^{n-1} + \dots + #1_1 x + #1_0}
\newcommand{\Zn}{\mathbb{Z}/n\mathbb{Z}}
\newcommand{\Rn}{\mathbb{R}^n}
\newcommand{\Fn}{\mathbb{F}^n}
\newcommand{\Cn}{\mathbb{C}^n}
\newcommand{\Rm}{\mathbb{R}^m}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Co}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Ha}{\mathbb{H}}
\newcommand{\ihat}{\mathbb i}
\newcommand{\jhat}{\mathbb j}
\newcommand{\khat}{\mathbb k}
\begin{document}
\frontmatter

\begin{titlepage}
%	\centering
%	{\huge\addfontfeatures{LetterSpace=5} CLASES DE ÁLGEBRA \liningnums 3}\\[1em]
%	{\Large{\scshape sep-dic} 2019}\\
%	\vfill
%	{\large Jhonny Lanzuisi, 15\,10759}\\[.7em]
%	{\large\ttfamily jalb97@gmail.com}
%	\vfill
%	Universidad Simón Bolívar \hfill Caracas, Venezuela
\end{titlepage}

%\begingroup
%% a \clearpage will close the group and restore the meaning
%\let\clearpage\endgroup
\tableofcontents
\begin{flushleft}
	\begin{tabular}[c]{rlr} 
%		\addlinespace[.5em]
		\multicolumn{3}{l}{\Large\itshape Evaluaciones} \\[1em]
		{ 1}er Parcial: & Semana 6 &({40}\%) \\
		{ 2}do Parcial: & Semana 11 &({50}\%) \\
		 Problemarios: & Antes de parcial &({10}\%) \\
	\end{tabular}
\end{flushleft}
%\twocolumn
\mainmatter

\chapter{Normas y Productos Internos}

\section{Normas}
%\clase{1}{Martes}{17/12}
\noindent
\begin{defi}[norma]
	Sea $\mathcal{V}$ un espacio vectorial real o complejo. Una norma sobre $\V$ es una función $\norm\colon\V\to\R$ tal que, para todo $\mathsf{x, y}\in\V$ y $\lambda$ un escalar,
	\begin{enumerate}
		\item $\Norm{\ve x}>0$ y $\Norm{\ve x} = 0$ si, y solo si, $\ve x = 0$.
		\item $\Norm{\lambda\ve x} = |\lambda|\Norm{\ve x}$
		\item $\Norm{\ve x+\ve y} \leq \Norm{\ve{x}} + \Norm{\ve y}$.
	\end{enumerate}
\end{defi}

\noindent
En un espacio vectorial $\V$ que posee una norma se puede definir la noción de distancia entre dos puntos $\ve{x,y}\in\V$ como $\Norm{\ve x-\ve y}$. $\mathscr{x}x$

\begin{ejem}
	La \emph{norma canónica} de $\Rn$ esta dada, para todo $\ve x=(\dt{x}{,})$, por
	\[ \Norm{\dt{x}{,}} = \sqrt{\dt{x^2}{+}}. \]
	El hecho de que esta norma cumple con las propiedades (1) y (2) de la definición anterior es inmediato debido a las propiedades de las raíces cuadradas reales. La propiedad (3) es menos evidente, la demostraremos mas adelante con ayuda del producto interno.
\end{ejem}

\begin{ejem}
	En $\mathbb{C}$ definimos:
	\[ \Norm{\dt{x}{,}} = \sqrt{|x_1|^2+\dots+|x_n|^2}. \]
	Al igual que antes, las propiedades (1) y (2) son consecuencia de las propeidades de las raices reales.
\end{ejem}

\begin{ejem}
	En $\Rn$ definimos:
	\[ \Norm{\dt{x}{,}} = \max(|x_1|,\dots,|x_n|). \]
	Veamos que esta norma cumple con las tres propiedades:
	\begin{enumerate}
		\item Dado que $|x_1|,\dots,|x_n|$ son todos positivos, el mayor de ellos también lo es. Si $\max(|x_1|,\dots,|x_n|) = 0$ es evidente que $x=0$, el recíproco es igual de fácil.
		\item Sea $|x_k|\,(1\leq k\leq n)$ el mayor de los $|x_1|,\dots,|x_n|$. Entonces
		\[ |cx_k| = |c||x_k| \geq |c||x_i| \quad\text{para todo $1\leq k\leq n$}. \]
		\item Consideremos el vector \textsc{suma}:
		\[ \ve x+\ve y = (x_1+y_1,\dots,x_n+y_n). \]
		Supongamos que $\max(\ve x+\ve y) = |x_k+y_j|$ con $1\leq k,j\leq n$. Entonces
		\[ |x_k+y_j|\leq|x_k|+|y_j|\leq\max(\ve x) + \max(\ve y). \]
	\end{enumerate}
\end{ejem}
\begin{ejem}
	En $\Rn$ definimos
	\[ \Norm{\dt{x}{,}} = \sum_{k=1}^{n} |x_k|. \]
\end{ejem}
\section{Producto interno}
\begin{defi}[producto interno]
	Sea $\V$ un espacio vectorial real o complejo. Un producto interno real sobre $\V$ es una función $\iprod\colon\V\t\V\to\R$ tal que, para todo $\ve{x,y,z}\in\V$ y $\lambda$ un escalar,
	\begin{enumerate}
		\item $\Iprod{\ve x}{\ve x}>0$ y $\Iprod{\ve x}{\ve x} = 0$ si, y solo si, $\ve x=0$.
		\item $\Iprod{\ve x}{\ve y} = \overline{\Iprod{\ve y}{\ve x}}$.
		\item $\Iprod{\lambda\ve x}{\ve y} = \lambda\Iprod{\ve x}{\ve y}$.
		\item $\Iprod{\ve x+\ve z}{\ve y} = \Iprod{\ve x}{\ve y} + \Iprod{\ve z}{\ve y}$.
	\end{enumerate}
Si $\V$ es de dimensión finita lo llamaremos \emph{espacio euclídeo}.
\end{defi}

Nótese que las propiedades (2) y (3) implican
\begin{align*}
	\Iprod{\ve x}{\lambda \ve y} &= \overline{\Iprod{\lambda\ve y}{\ve x}} \\
						 		 &= \overline{\lambda}\,\overline{\Iprod{\ve y}{\ve x}} \\
						 		 &= \overline{\lambda}\Iprod{\ve x}{\ve y}.
\end{align*}
De forma similar las propiedades (2) y (4) implican
\begin{align*}
	\Iprod{\ve x}{\ve y+\ve z} &= \overline{\Iprod{\ve y+\ve z}{\ve x}} \\
							&= \overline{\Iprod{\ve y}{\ve x}} + \overline{\Iprod{\ve z}{\ve x}} \\
							&= \Iprod{\ve x}{\ve y} + \Iprod{\ve x}{\ve z}.
\end{align*}

Por todo lo anterior los productos internos son transformaciones lineales.

\begin{ejem}
	En $\Rn$ el \emph{producto interno canónico} esta dado por
	\[ \Iprod{\ve x}{\ve y} = \Iprod{(\dt{x}{,})}{(\dt{y}{,})} = \sum_{k=1}^{n} x_ky_k.\]
	Para este producto interno las propiedades (1)-(4) no son difíciles de verificar.
\end{ejem}

%\clase{2}{Lunes}{23}
%({\scshape nada nuevo})
%\clase{3}{Martes}{24}
\begin{ejem}
	En $\Cn$ el \emph{producto interno canónico} esta dado por
	\[ \Iprod{\ve x}{\ve y} = \Iprod{(\dt{x}{,})}{(\dt{y}{,})} = \sum_{k=1}^{n} x_k\overline{y_k}.\]
	al igual que el ejemplo anterior las propiedades (1)-(4) no son difíciles de verificar.
\end{ejem}
\begin{ejem}
	En $\V= M_{mn}(\Co)$ definimos un producto interno como
	\[ \Iprod{A}{B} = \traz(AB^\ast) \]
	donde $A,B\in M_{mn}(\Co)$ y $B^\ast$ es la \emph{adjunta} (transpuesta de la conjugada) de $B$. Veamos que esta es en efecto un producto interno.
	Para la propiedad (1), notemos que
	\begin{align*}
		\Iprod{A}{A}  &= \traz(AA^\ast) \\
					  &= \sum_{i=1}^{m} AA^\ast_{(ii)} \\
					  &= \sum_{i=1}^{m}\sum_{k=1}^{n} A_{(ik)}A^\ast_{(ki)} \\
					  &= \sum_{i=1}^{m}\sum_{k=1}^{n} A_{(ik)}\overline{A}_{(ik)} \\
					  &= \sum_{i=1}^{m}\sum_{k=1}^{n} A^2_{(ik)}
	\end{align*}
	de donde es claro que $\Iprod{A}{A}>0$ y $\Iprod{A}{A} = 0$ si, y solo si, la suma de los $A_{(ik)}$ es cero, es decir, si $A=0$.
	
	Para (2), veamos que
	\begin{align*}
		\overline{\Iprod{A}{B}} &= \overline{\traz(AB^\ast)} \\
					 			&= \sum_{i=1}^{m}\sum_{k=1}^{n} \overline{A}_{(ik)}\overline{B^\ast}_{(ki)} \\
					 			&= \sum_{i=1}^{m}\sum_{k=1}^{n} \overline{A}_{(ik)}^\mathrm t(B^\mathrm t)^\mathrm t_{(ki)} \\
					 			&= \sum_{i=1}^{m}\sum_{k=1}^{n} B_{(ik)}A_{(ki)}^\ast
	\end{align*}
\end{ejem}
\chapter{Formas Bilineales y Cuadráticas}

El objeto central de esta capítulo, las \emph{formas bilineales}, son una generalización natural del concepto de producto interno. La ventaja de aquellas \textsf{bilineales} sobre estos es que las formas bilineales se encuentran en el cáculo multivariable y la geometría diferencial en lugares donde \emph{no} se tiene un producto interno.
%\makeatletter
%\@chapapp
%\makeatother

\section{Formas Bilineales}

\begin{defi}
	Una función $B:\V\t\V\to\F$, donde $\V$ es un espacio vectorial y $\F$ un cuerpo de escalares, es una \textup{\textsf{\textsc{forma bilineal}}} si $B$ es lineal en cada componente cuando se deja la otra fija, es decir, si para todo $\ve x_i,\ve y_i\in\V (i=1,2)$ y $\lambda\in\F$ se tiene que
	\begin{align*}
		B(\lambda \ve x_1+\ve x_2,\ve y) &= \lambda B(\ve x_1,\ve y) + B(\ve x_2,\ve y) \quad\text{y} \\
		B(\lambda \ve x, \ve y_1 + \ve y_2) &= \lambda B(\ve x,\ve y_1) + B(\ve x,\ve y_2).
	\end{align*}
	Diremos además que la forma bilineal es \textup{\textsc{simétrica}} si $B(\ve x,\ve y) = B(\ve y,\ve x)$.
\end{defi}

Al conjunto de todas $A\mathcal{A}B\mathcal{B}$ las formas bilineales sobre $\V$ lo llamaremos $\vcsp B(\V)$. Nótese que un producto interno es una forma bilineal si el cuerpo de escalares es real pero no si es complejo, debido a la conjugación necesaria en la linealidad de los productos internos complejos (en este caso se le llama \emph{bilineal conjugada}).

Hay un ejemplo peculiar de una forma bilineal que conviene enunciar como un lema, pues nos será útil más adelante.

\begin{lem}
	Para cualquier matríz $A\in\Mn F$ la función $B:\Fn\t\Fn\to F$ definida por
	\[ B(\ve x,\ve y) = \ve x^tA\ve y \]
	es una forma bilineal.
\end{lem}
\begin{proof}
	Notemos primero que como $\ve x$ es una matríz $1\t n$ y $\ve y$ es una matríz $n\t 1$ el producto $\ve x^tA\ve y$ es una matríz $1\t 1$ y por lo tanto tiene sentido asociarlo con un escalar en $F$.
\end{proof}

\section{Formas Cuadráticas}

\subsection{Ejercicios}
\begin{ejer}
	Encuentre un polinomio cuadrático diagonal isométrico a:
	\begin{enumerate}
		\item $x^2-xy+y^2+xz-z^2$.
		\item $xy-xz-yz$.
		\item $xz+yw$.
	\end{enumerate}
\end{ejer}
\begin{sol}
	 \textsc{consideremos primero} el polinomio $x^2-xy+y^2+xz-z^2$. La matriz simétrica $S$ asociada a el ha de cumplir que $s_{ij}=1/2(a_{ij}+a_{ji})$ donde los $a_{ij}$ son los coeficientes de nuestro polinimio cuadrático. Se sigue entonces que
	 \[ S = \begin{pmatrix}
	 \phantom{-}1 & -1/2 & \phantom{-}1/2 \\
	 -1/2 & \phantom{-}1 & \phantom{-}0 \\
	 \phantom{-}1/2 & \phantom{-}0 & -1
	 \end{pmatrix}. \]
	 Por lo que la forma bilineal asociada $\Bform_S$ viene dada, para $v=(a_1,a_2,a_3)$ y $w=(b_1,b_2,b_3)$, por
	 \begin{align*}
	 	v^tAw &= (a_1,a_2,a_3) \begin{pmatrix}
	 	\phantom{-}1 & -1/2 & \phantom{-}1/2 \\
	 	-1/2 & \phantom{-}1 & \phantom{-}0 \\
	 	\phantom{-}1/2 & \phantom{-}0 & -1
	 	\end{pmatrix} \begin{pmatrix}
	 	b_1 \\ b_2 \\ b_3
	 	\end{pmatrix} \\
	 	&= (a_1,a_2,a_3) \begin{pmatrix}
	 	b_1-b_2/2+b_3/2 \\
	 	-b_1/2+b_2 \\
	 	\phantom{-}b_1/2 - b_3
	 	\end{pmatrix} \\
	 	&= a_1(b_1-\frac{b_2}{2}+\frac{b_3}{2}) + a_2(-\frac{b_1}{2}+b_2) + a_3(\frac{b_1}{2} - b_3). 
%	 	&= a_1b_1 -\frac{a_1b_2}{2} + \frac{a_1b_3}{2} - \frac{a_2b_1}{2} + a_2b_2 + \frac{a_3b_1}{2} - a_3b_3 \\
	 \end{align*}
	 Ahora solo hace falta diagonalizar la matriz $S$ para obtener el polinomio diagonal buscado. Sea $v_1 = (1,0,0)$ y notemos que $\bform{v_1}{v_1}_S = 1$. El complemento ortogonal $v_1^\perp$ viene dado por
	 \[ b_1-\frac{b_2}{2}+\frac{b_3}{2} = 0 \]
	 que implica
	 \[ v_1^\perp = \gen\left\{ b_2\begin{pmatrix}
	 1/2 \\ 1 \\ 0
	 \end{pmatrix} + b_3\begin{pmatrix}
	 -1/2 \\ \phantom{-}0 \\ \phantom{-}1
	 \end{pmatrix} \right\}. \]
	 Notemos que $v_2=(1/2,1,0)$ es tal que $\bform{v_2}{v_2}_S = 3/4$. Y su complemento ortogonal $v_2^\perp$ viene dado por
	 \[ \frac{3b_2}{4}+ \frac{b_3}{4} = 0\]
	 y nuestro tercer vector $v_3$ es cualquier solución no trivial del sistema
	 \[ \begin{cases}\displaystyle
	 b_1-\frac{b_2}{2}+\frac{b_3}{2} = 0 \\[.5em] \displaystyle
	 \frac{3b_2}{4}+ \frac{b_3}{4} = 0
	 \end{cases} \]
	 como por ejemplo $v_3 = (2,1,-3)$. Entonces la matriz 
	 \[ P = \begin{pmatrix}
	 1 & 1/2 & 2\\
	 0 & 1 & 1\\
	 0 & 0 & -3
	 \end{pmatrix} \]
	 es tal que
	 \[ P^tSP = \begin{pmatrix}
	 1 & 0 & 0 \\
	 0 & 3/4 & 0 \\
	 0 & 0 & -12 \\
	 \end{pmatrix} \]

Y finalmente nuestro polinomio $x^2-xy+y^2+xz-z^2$ es isométrico a $u^2+\frac{3}{4}v^2 -12 w^2$.

\textsc{consideremos en segundo lugar} el polinomio $xy-xz-yz$. La matriz simétrica $S$ asociada a el es
\[ S = \begin{pmatrix}
0 & 1 & -1 \\
1 & 0 & -1 \\
-1 & -1 & 0
\end{pmatrix} \]
y la forma bilineal $\Bform_S$ viene dada,  para $v=(a_1,a_2,a_3)$ y $w=(b_1,b_2,b_3)$, por
\begin{align*}
v^tAw &= (a_1,a_2,a_3) \begin{pmatrix}
0 & 1 & -1 \\
1 & 0 & -1 \\
-1 & -1 & 0
\end{pmatrix} \begin{pmatrix}
b_1 \\ b_2 \\ b_3
\end{pmatrix} \\
&= (a_1,a_2,a_3) \begin{pmatrix}
b_2-b_3 \\
b_1-b_3 \\
-b_1-b_2
\end{pmatrix} \\
&= a_1(b_2-b_3) + a_2(b_1-b_3) + a_3(-b_1-b_2).
\end{align*}
Ahora solo hace falta diagonalizar la matriz $S$ para obtener el polinomio diagonal buscado. Sea $v_1 = (1,1,0)$ notemos que $\bform{v_1}{v_1}_S = 1$, y su complemento ortogonal $v_1^\perp$ esta dado por
\[ b_1+b_2-2b_3 = 0 \]
que implica
\[ v_1^\perp = \gen\left\{ b_2\begin{pmatrix}
-1 \\1 \\0 
\end{pmatrix}  + b_3\begin{pmatrix}
2 \\ 0 \\ 1
\end{pmatrix}\right\}. \]
Tomemos ahora $v_2 = (-1,1,0)$ y notemos que $\bform{v_2}{v_2}_S = -1$. Su complemento ortogonal $v_2^\perp$ esta dado por
\[ b_1-b_2 = 0 \]
Nuestro último vector $v_3$ es cualquier solución no trivial al sistema 
\[ \begin{cases}
b_1+b_2-2b_3 = 0 \\
b_1-b_2 = 0
\end{cases} \]
como por ejemplo $v_3=(1,1,1)$. Y la matriz $P$ dada por
\[ P = \begin{pmatrix}
1 & -1 & 1\\
1 & 1 & 1\\
0 & 0 & 1\\
\end{pmatrix} \]
es tal que
\[ P^tSP = \begin{pmatrix}
2 & 0 & 0 \\
0 & -2 & 0 \\
0 & 0 & -2
\end{pmatrix} \]
y finalmente nuestro polinomio $xy-xz-yz$ es isométrico a $2v^2-2u^2-2w^2$.

\textsc{consideremos en tercer lugar} el polinomio $xz+yw$. La matriz simétrica $S$ asociada a el es
\[ S = \begin{pmatrix}
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0
\end{pmatrix} \]
y la forma bilineal $\Bform_S$ viene dada,  para $v=(a_1,a_2,a_3,a_4)$ y $w=(b_1,b_2,b_3,b_4)$, por
\begin{align*}
v^tAw &= (a_1,a_2,a_3,a_4)  \begin{pmatrix}
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0
\end{pmatrix} \begin{pmatrix}
b_1 \\ b_2 \\ b_3 \\ b_4
\end{pmatrix} \\
&= (a_1,a_2,a_3,a_4)  \begin{pmatrix}
b_3 \\ b_4 \\ b_1\\ b_2 
\end{pmatrix} \\
&= a_1b_3 + a_2b_4 + a_3b_1 + a_4b_2.
\end{align*}
Ahora solo hace falta diagonalizar la matriz $S$ para obtener el polinomio diagonal buscado. Sea $v_1 = (1,0,1,0)$ notemos que $\bform{v_1}{v_1}_S = 1$, y su complemento ortogonal $v_1^\perp$ esta dado por
\[ b_3+b_1 = 0 \]
que implica
\[ v_1^\perp = \gen \left\{ b_3\begin{pmatrix}
-1 \\ 0 \\ 1 \\ 0
\end{pmatrix}+ b_2\begin{pmatrix}
0 \\ 1 \\ 0 \\ 0
\end{pmatrix}+b_4\begin{pmatrix}
0 \\ 0 \\ 0 \\ 1
\end{pmatrix} \right\}. \]
Tomemos ahora $v_2 = (-1,0,1,0)$ y notemos que $\bform{v_2}{v_2}_S = -1$. Su complemento ortogonal $v_2^\perp$ esta dado por
\[ b_1-b_3 = 0. \]
Ahora nuestor vector $v_3$ es cualqueir solución al sistema
\[ \begin{cases}
b_3+b_1 = 0 \\
b_1-b_3 = 0
\end{cases} \]
como por ejemplo $v_3 = (0,1,0,1)$. Su complemento ortogonal $v_3^\perp$ esta dado por
\[ b_4+b_2 = 0. \]
El último vector $v_4$ es cualquier solución al sistema 
\[ \begin{cases}
b_3+b_1 = 0 \\
b_1-b_3 = 0 \\
b_4+b_2 = 0
\end{cases} \]
como $v_4 = (0,1,0,-1)$. Y la matriz $P$ dada por
\[ P = \begin{pmatrix}
1 & -1& 0& 0\\
0 & 0& 1& 1\\
1 & 1& 0& 0\\
0 & 0& 1& -1\\
\end{pmatrix} \]
es tal que 
\[ P^tAP =  \begin{pmatrix}
2 & 0& 0& 0\\
0 & -2& 0& 0\\
0 & 0& 2& 0\\
0 & 0& 0& -2\\
\end{pmatrix} \]
y nuestro polinomio $xz+yw$ es isométrico a $2t^2-2u^2+2v^2-2w^2$.
\end{sol}

\begin{ejer}
	Encontrar la forma cuadrática (expresada como un polinomio) asociada a cada una de las siguientes matrices simétricas:
	\[ S_1=\begin{pmatrix}
	2 & 4 \\ 4 & 1
	\end{pmatrix} \quad S_2=\begin{pmatrix}
	1 & 2 &1 \\
	1 & 0 & 3 \\
	1 & 3 & 2
	\end{pmatrix}\quad S_3=\begin{pmatrix}
	1 & 3 &4 \\
	3 & 0 & 1\\
	4 & 1 & 2
	\end{pmatrix} \]
\end{ejer}
\begin{sol}
	Para cada una de las matrices $S_i$ el polinomio cuadrático asociado a ellas se calcula como:
	\[ q_1 = v^tS_1v\quad q_2=v^tS_2v\quad q_3=v^tS_3v, \]
	donde $v$ es un vector de $\R^2$ en el caso de $q_1$ y un vector de $\R^3$ en el caso de $q_2$ y $q_3$.
	
	Entonces,
	\begin{align*}
		q_1 &=  v^tS_1v \\
			&= (x,y) \begin{pmatrix}
			2 & 4 \\ 4 & 1
			\end{pmatrix} \begin{pmatrix}
			x \\ y
			\end{pmatrix} \\
			&= (x,y) \begin{pmatrix}
			2x+4y \\
			4x+y
			\end{pmatrix} \\
			&= x(2x+4y) + y(4x+y)\\
			&= 2x^2+4xy+4yx+y^2 \\
			&= 2x^2+8xy+y^2.
	\end{align*}
	Similarmente,
	\begin{align*}
		q_2 &= v^tS_2v \\
			&= (x,y,z) \begin{pmatrix}
			1 & 2 &1 \\
			1 & 0 & 3 \\
			1 & 3 & 2
			\end{pmatrix} \begin{pmatrix}
			x \\ y \\ z
			\end{pmatrix} \\
			&= (x,y,z)\begin{pmatrix}
			x+2y+z \\
			x+3z \\
			x+3y+2z
			\end{pmatrix} \\
			&=x(x+2y+z) + y(x+3z) + z(x+3y+2z) \\
			&=x^2+2xy+xz+yx+3yz+zx+3yz+2z^2 \\
			&=x^2+3xy+2xz+6yz+2z^2.
	\end{align*}
	Y finalmente,
	\begin{align*}
		q_3 &= v^tS_3v \\
			&= (x,y,z)\begin{pmatrix}
			1 & 3 &4 \\
			3 & 0 & 1\\
			4 & 1 & 2
			\end{pmatrix}\begin{pmatrix}
			x \\ y \\ z
			\end{pmatrix} \\
			&= (x,y,z)\begin{pmatrix}
			x+3y+4z \\
			3x+z\\
			4x+y+2z
			\end{pmatrix} \\
			&= x(x+3y+4z) + y(3x+z) + z(4x+y+2z) \\
			&= x^2+3xy+4xz + 3xy + yz + 4xz + yz + 2z^2 \\
			&= x^2 +6xy+8xz+2yz+2z^2.
	\end{align*}
\end{sol}
\begin{ejer}
	Sea $q$ la forma cuadrática en $\F^2$ dada por $XY$. Encuentre una transformación lineal invertible $T:\F^2\to\F^2$ tal que
	\[ q\big(T(a,b)\big) = a^2-b^2. \]
\end{ejer}
\begin{sol}
	Consideremos la transformación $T:\F^2\to\F^2$ dada, para todo $(a,b)\in\F^2$, por $T(a,b) = (a-b,a+b)$. Para esta $T$ se tiene que 
	\[ q\big(T(a,b)\big) = (a-b)(a+b) = a^2-b^2. \]
	
	Además la transformación $T$ es inyectiva, pues $\ker(T)=\{0\}$, y sobreyectiva, puesto que para cualquier vector $v$ en $\F^2$ se pueden hallar elementos $a,b\in\F$ tales que $v=(a-b,a+b)$. La biyectividad implica entonces que $T$ es invertible (más aún, su inversa $T\inv:\F^2\to\F^2$ esta dada por $T\inv(x,y) = 1/2(x+y,y-x)$).
	
	Luego la $T$ dada satisface las condiciones del problema.
\end{sol}
\chapter[teorema de cauchy-hamilton]{Teorema de Cauchy-Hamilton}

\chapter[forma canónica de jordan]{Forma Canónica de Jordan}

\chapter[teorema de descomposición cíclica]{Teorema de Descomposición Cíclica}

\backmatter
\end{document}
